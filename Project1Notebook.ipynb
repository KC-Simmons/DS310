{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project1Notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOH8LkdePeaG"
      },
      "source": [
        "Imports the needed Python libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idddSGP6PXIy"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn import metrics \n",
        "from sklearn import linear_model\n",
        "import seaborn as sb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQNlQ7nmPp5J"
      },
      "source": [
        "Reads in the data sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8BSo5CjPl1D",
        "outputId": "dfbf48fa-cce2-4032-8ed6-8b465c788c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "source": [
        "x_test = pd.read_csv('x_test.csv')\n",
        "x_train = pd.read_csv('x_train.csv')\n",
        "y_train = pd.read_csv('y_train.csv')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-971741b8bc0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'x_test.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQHITy6_PzK9"
      },
      "source": [
        "Normalizes the data with the Standard Scaler from Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVeejjhzPuJS"
      },
      "source": [
        "x_train[x_train.columns] = StandardScaler().fit_transform(x_train[x_train.columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqe1EuBkP5_H"
      },
      "source": [
        "Drops columns that are highly correlated with other columns, correlations threshold of 0.6, and favors removing higher number columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtKF_MINP3GY"
      },
      "source": [
        "for column in x_train.columns[::-1]:\n",
        "    cor_target = abs(x_train.corr()[column])\n",
        "    rev_preds = cor_target[cor_target>0.6]\n",
        "    print(len(x_train.columns))\n",
        "    for i in range(len(rev_preds.index)):\n",
        "        col2remove = rev_preds.index[i]\n",
        "        if column != col2remove and int(column[-2:].strip()) < int(rev_preds.index[i][-2:].strip()):\n",
        "            x_train = x_train.drop(columns=[col2remove])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HH7EI61QJnM"
      },
      "source": [
        "Chooses the k best predictors for all k and then calculates the R^2, AIC, and BIC for the resulting models and finds the best one according to each criterion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3_7kf55QKYD"
      },
      "source": [
        "adjr2lst= []\n",
        "best_amt_preds = 0\n",
        "AIClst= [100000]\n",
        "best_amt_preds_AIC = 0\n",
        "BIClst= [100000]\n",
        "best_amt_preds_BIC = 0\n",
        "\n",
        "\n",
        "adjr2lassolst= []\n",
        "best_amt_preds_lasso = 0\n",
        "AIClassolst= [100000]\n",
        "best_amt_preds_lasso_AIC = 0\n",
        "BIClassolst= [100000]\n",
        "best_amt_preds_lasso_BIC = 0\n",
        "for krange in range(1,len(x_train.columns)+1):\n",
        "    pred_select = SelectKBest(score_func=f_regression, k=krange)\n",
        "    fit_pred_select = pred_select.fit_transform(x_train, y_train['Output'])\n",
        "    print(krange)\n",
        "    pred_support_list = pred_select.get_support()\n",
        "\n",
        "    best_model_x_train = pd.DataFrame({})\n",
        "    for i in range(len(pred_support_list)):\n",
        "        if pred_support_list[i] == True:\n",
        "            for j in range(len(x_train.columns)):\n",
        "                if i==j:\n",
        "                    best_model_x_train['{}'.format(x_train.columns[j])] = x_train[x_train.columns[j]]\n",
        "\n",
        "    reg= linear_model.LinearRegression().fit(best_model_x_train,y_train['Output'])\n",
        "    y_pred = reg.predict(best_model_x_train)\n",
        "    adjr2 = 1-(1-metrics.r2_score(y_train['Output'], y_pred))*(len(best_model_x_train)-1)/(len(best_model_x_train)- len(best_model_x_train.columns)-1)\n",
        "    sse=0\n",
        "    for i in range(len(y_pred)):\n",
        "        sse += (y_pred[i] - y_train['Output'][i])**2\n",
        "    AIC = 2*len(best_model_x_train.columns) + len(best_model_x_train)*np.log(sse/(len(best_model_x_train) - len(best_model_x_train.columns)))\n",
        "    BIC = len(best_model_x_train)*np.log(sse) + len(best_model_x_train.columns)*np.log(sse/(len(best_model_x_train) - len(best_model_x_train.columns)))\n",
        "\n",
        "\n",
        "    reglasso = linear_model.Lasso().fit(best_model_x_train,y_train['Output'])\n",
        "    y_pred_lasso = reglasso.predict(best_model_x_train)\n",
        "    adjr2lasso = 1-(1-metrics.r2_score(y_train['Output'], y_pred_lasso))*(len(best_model_x_train)-1)/(len(best_model_x_train)- len(best_model_x_train.columns)-1)\n",
        "    sselasso = 0\n",
        "    for i in range(len(y_pred)):\n",
        "        sselasso += (y_pred_lasso[i] - y_train['Output'][i])**2\n",
        "    AIClasso = 2*len(best_model_x_train.columns) + len(best_model_x_train)*np.log(sselasso/(len(best_model_x_train) - len(best_model_x_train.columns)))\n",
        "    BIClasso = len(best_model_x_train)*np.log(sselasso) + len(best_model_x_train.columns)*np.log(sselasso/(len(best_model_x_train) - len(best_model_x_train.columns)))\n",
        "\n",
        "    adjr2lassolst.append(adjr2lasso)\n",
        "    if adjr2lasso >= max(adjr2lassolst):\n",
        "        new_x_train_lasso = best_model_x_train\n",
        "        best_amt_preds_lasso = krange\n",
        "    print('Adj. R^2 Lasso:', adjr2lasso)\n",
        "\n",
        "    adjr2lst.append(adjr2)\n",
        "    if adjr2 >= max(adjr2lst):\n",
        "        new_x_train = best_model_x_train\n",
        "        best_amt_preds = krange\n",
        "    print('Adj. R^2:', adjr2)\n",
        "    print('------------\\n')\n",
        "\n",
        "\n",
        "    if AIClasso <= min(AIClassolst) and krange > 1:\n",
        "        AIClassolst.append(AIClasso)\n",
        "        new_x_train_lasso_AIC = best_model_x_train\n",
        "        best_amt_preds_lasso_AIC = krange\n",
        "    print('AIC Lasso:', AIClasso)\n",
        "\n",
        "\n",
        "    if AIC <= min(AIClst) and krange > 1:\n",
        "        AIClst.append(AIC)\n",
        "        new_x_train_AIC = best_model_x_train\n",
        "        best_amt_preds_AIC = krange\n",
        "    print('AIC:', AIC)\n",
        "    print('------------\\n')\n",
        "\n",
        "    if BIClasso <= min(BIClassolst) and krange > 1:\n",
        "        BIClassolst.append(BIClasso)\n",
        "        new_x_train_lasso_BIC = best_model_x_train\n",
        "        best_amt_preds_lasso_BIC = krange\n",
        "    print('BIC Lasso:', BIClasso)\n",
        "\n",
        "    if BIC <= min(BIClst) and krange > 1:\n",
        "        BIClst.append(BIC)\n",
        "        new_x_train_BIC = best_model_x_train\n",
        "        best_amt_preds_BIC = krange\n",
        "    print('BIC:', BIC)\n",
        "    print('------------\\n')\n",
        "\n",
        "print(max(adjr2lst))\n",
        "print(best_amt_preds)\n",
        "print(max(adjr2lassolst))\n",
        "print(best_amt_preds_lasso)\n",
        "\n",
        "print(min(AIClst))\n",
        "print(best_amt_preds_AIC)\n",
        "print(min(AIClassolst))\n",
        "print(best_amt_preds_lasso_AIC)\n",
        "\n",
        "print(min(BIClst))\n",
        "print(best_amt_preds_BIC)\n",
        "print(min(BIClassolst))\n",
        "print(best_amt_preds_lasso_BIC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1blE30rxQsvB"
      },
      "source": [
        "Finds the mean MSE of many models over a 1000 trials of by spliting the training data given into training and testing data.  Then calculates the average MSE of the best models produced in the last section to find the best model at predicting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2sKRgSHQs6e"
      },
      "source": [
        "n= 1000\n",
        "for j in range(1,n+1):\n",
        "\n",
        "    leanModelReg = linear_model.LinearRegression()\n",
        "    X_train2, X_test2, y_train2, y_test2 = train_test_split(new_x_train, y_train['Output'], test_size = .3, random_state = j)\n",
        "    leanModelReg.fit(X_train2,y_train2)\n",
        "    y_pred2 = leanModelReg.predict(X_test2)\n",
        "    leanMSEtotal += metrics.mean_squared_error(y_test2,y_pred2)\n",
        "    #print(leanModelReg.score(X_test2,y_test2))\n",
        "    #print('MSE:', metrics.mean_squared_error(y_test2,y_pred2))\n",
        "\n",
        "    leanModelRegAIC = linear_model.LinearRegression()\n",
        "    X_train2, X_test2, y_train2, y_test2 = train_test_split(new_x_train_AIC, y_train['Output'], test_size = .3, random_state = j)\n",
        "    leanModelRegAIC.fit(X_train2,y_train2)\n",
        "    y_pred2 = leanModelRegAIC.predict(X_test2)\n",
        "    leanMSEtotalAIC += metrics.mean_squared_error(y_test2,y_pred2)\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(1,11):\n",
        "        #print('alpha=',i*0.1)\n",
        "        lassoModelReg = linear_model.Lasso(alpha = 0.3*i,max_iter=10000)\n",
        "        X_train2, X_test2, y_train2, y_test2 = train_test_split(new_x_train_lasso, y_train['Output'], test_size = .3,random_state = j)\n",
        "        lassoModelReg.fit(X_train2,y_train2)\n",
        "        y_pred2 = lassoModelReg.predict(X_test2)\n",
        "        #print(lassoModelReg.score(X_test2,y_test2))\n",
        "        lassoMSEtotal[i-1] += metrics.mean_squared_error(y_test2,y_pred2)\n",
        "        #print('MSE:', metrics.mean_squared_error(y_test2,y_pred2))\n",
        "\n",
        "\n",
        "    for i in range(1,11):\n",
        "        #print('alpha=',i*0.1)\n",
        "        lassoModelRegAIC = linear_model.Lasso(alpha = 0.1*i)\n",
        "        X_train2, X_test2, y_train2, y_test2 = train_test_split(new_x_train_lasso_AIC, y_train['Output'], test_size = .3,random_state = j)\n",
        "        lassoModelRegAIC.fit(X_train2,y_train2)\n",
        "        y_pred2 = lassoModelRegAIC.predict(X_test2)\n",
        "        #print(lassoModelReg.score(X_test2,y_test2))\n",
        "        lassoMSEtotalAIC[i-1] += metrics.mean_squared_error(y_test2,y_pred2)\n",
        "        #print('MSE:', metrics.mean_squared_error(y_test2,y_pred2))\n",
        "\n",
        "    fullModelReg = linear_model.LinearRegression()\n",
        "    X_train2, X_test2, y_train2, y_test2 = train_test_split(x_train, y_train['Output'], test_size = .3, random_state = j)\n",
        "    fullModelReg.fit(X_train2,y_train2)\n",
        "    y_pred2 = fullModelReg.predict(X_test2)\n",
        "    #print(fullModelReg.score(X_test2,y_test2))\n",
        "    semifullMSEtotal += metrics.mean_squared_error(y_test2,y_pred2)\n",
        "    #print('MSE:', metrics.mean_squared_error(y_test2,y_pred2))\n",
        "\n",
        "print(leanMSEtotal/n)\n",
        "lassoMSEtotal[:] = [(x / n) for x in lassoMSEtotal]\n",
        "print(lassoMSEtotal)\n",
        "print(semifullMSEtotal/n)\n",
        "\n",
        "print(leanMSEtotalAIC/n)\n",
        "lassoMSEtotalAIC[:] = [(x / n) for x in lassoMSEtotalAIC]\n",
        "print(lassoMSEtotalAIC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVNSiB_nRJuW"
      },
      "source": [
        "Creates a new model using the parameters that gave the lowest mean MSE (Lasso, alpha 0.5, AIC criterion)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5kh_78qRJLo"
      },
      "source": [
        "allDataLeanReg = linear_model.Lasso(alpha=0.5,max_iter=1000000,tol=1e-6)\n",
        "allDataLeanReg.fit(new_x_train_lasso_AIC,y_train['Output'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn76SD1kRjNT"
      },
      "source": [
        "Drops the unnescesary predictors from the x_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIzq6l9FRjYh"
      },
      "source": [
        "for column in x_test.columns:\n",
        "    if not (column in new_x_train_lasso_AIC.columns):\n",
        "        x_test = x_test.drop(columns=column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ezNtR0GRqZ1"
      },
      "source": [
        "Standardizes x_test data with Sklearn's Standard Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ENUjOpYRqkH"
      },
      "source": [
        "x_test[x_test.columns] = StandardScaler().fit_transform(x_test[x_test.columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhvVGXZHR0Pg"
      },
      "source": [
        "Writes the data to pandas data frame and writes to resulting csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryP6vOWLR0Yl"
      },
      "source": [
        "Submission = pd.DataFrame({\n",
        "    'Sl. No.':range(1,201),\n",
        "    'Output':y_pred\n",
        "})\n",
        "Submission.to_csv('Submission_Project1_KeithSimmons',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}